{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos Ensembles realizan entrenamientos con submodelos para luego promediar el entrenamiento o tomar el más frecuente, para hacer la prediccion\n",
    "\n",
    "Los algoritmos con casillas de más valor (color más intenso) son los mas recomendados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    Según distintos benchmarks (papers, kaggle.com) los **algoritmos de uso general** que tienen más veces la mejor performance son: **Gradient Boosted Trees, Random Forest y SVM**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../vol/img/benchmark_algs.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor     #Arbol normal\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=2)    #max_depht profundidad del arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv('X_opening.csv')\n",
    "y = X['worldwide_gross']\n",
    "X = X.drop('worldwide_gross',axis=1)\n",
    "X = X.drop('budget',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n                      max_features=None, max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, presort='deprecated',\n                      random_state=None, splitter='best')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz       #Exportar el grapho, para hacerlo compatible con graghviz\n",
    "\n",
    "treedot = export_graphviz(model,\n",
    "                         out_file=None,\n",
    "                         feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'digraph Tree {\\nnode [shape=box] ;\\n0 [label=\"opening_gross <= 42520512.0\\\\nmse = 4.317194836730146e+16\\\\nsamples = 1642\\\\nvalue = 137722820.592\"] ;\\n1 [label=\"opening_gross <= 22074047.0\\\\nmse = 1.3666950687751852e+16\\\\nsamples = 1500\\\\nvalue = 93350921.809\"] ;\\n0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\\n2 [label=\"mse = 5245377637828732.0\\\\nsamples = 1243\\\\nvalue = 63983310.656\"] ;\\n1 -> 2 ;\\n3 [label=\"mse = 3.005220451257739e+16\\\\nsamples = 257\\\\nvalue = 235389601.436\"] ;\\n1 -> 3 ;\\n4 [label=\"opening_gross <= 70284356.0\\\\nmse = 1.1435073341307494e+17\\\\nsamples = 142\\\\nvalue = 606440061.254\"] ;\\n0 -> 4 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\\n5 [label=\"mse = 3.693166293648493e+16\\\\nsamples = 85\\\\nvalue = 438524597.882\"] ;\\n4 -> 5 ;\\n6 [label=\"mse = 1.2505386366560589e+17\\\\nsamples = 57\\\\nvalue = 856840313.649\"] ;\\n4 -> 6 ;\\n}'"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "treedot       #Sin grachviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<graphviz.files.Source at 0x17cdf788248>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"828pt\" height=\"269pt\"\r\n viewBox=\"0.00 0.00 828.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-265 824,-265 824,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\"><title>0</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"492.5,-261 298.5,-261 298.5,-193 492.5,-193 492.5,-261\"/>\r\n<text text-anchor=\"middle\" x=\"395.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">opening_gross &lt;= 42520512.0</text>\r\n<text text-anchor=\"middle\" x=\"395.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 4.317194836730146e+16</text>\r\n<text text-anchor=\"middle\" x=\"395.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1642</text>\r\n<text text-anchor=\"middle\" x=\"395.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 137722820.592</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\"><title>1</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"387,-157 186,-157 186,-89 387,-89 387,-157\"/>\r\n<text text-anchor=\"middle\" x=\"286.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">opening_gross &lt;= 22074047.0</text>\r\n<text text-anchor=\"middle\" x=\"286.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 1.3666950687751852e+16</text>\r\n<text text-anchor=\"middle\" x=\"286.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1500</text>\r\n<text text-anchor=\"middle\" x=\"286.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 93350921.809</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M360.111,-192.884C350.402,-183.798 339.766,-173.845 329.673,-164.4\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"331.778,-161.577 322.085,-157.299 326.995,-166.688 331.778,-161.577\"/>\r\n<text text-anchor=\"middle\" x=\"322.914\" y=\"-178.586\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\"><title>4</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"606,-157 405,-157 405,-89 606,-89 606,-157\"/>\r\n<text text-anchor=\"middle\" x=\"505.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">opening_gross &lt;= 70284356.0</text>\r\n<text text-anchor=\"middle\" x=\"505.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 1.1435073341307494e+17</text>\r\n<text text-anchor=\"middle\" x=\"505.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 142</text>\r\n<text text-anchor=\"middle\" x=\"505.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 606440061.254</text>\r\n</g>\r\n<!-- 0&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M431.214,-192.884C441.108,-183.709 451.956,-173.65 462.23,-164.123\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"464.636,-166.665 469.589,-157.299 459.876,-161.532 464.636,-166.665\"/>\r\n<text text-anchor=\"middle\" x=\"468.646\" y=\"-178.582\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\"><title>2</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"173,-53 0,-53 0,-0 173,-0 173,-53\"/>\r\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 5245377637828732.0</text>\r\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1243</text>\r\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 63983310.656</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M216.55,-88.9485C194.864,-78.7021 171.1,-67.4737 149.887,-57.4503\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"151.189,-54.1943 140.652,-53.0867 148.198,-60.5234 151.189,-54.1943\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\"><title>3</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"385.5,-53 191.5,-53 191.5,-0 385.5,-0 385.5,-53\"/>\r\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 3.005220451257739e+16</text>\r\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 257</text>\r\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 235389601.436</text>\r\n</g>\r\n<!-- 1&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M287.2,-88.9485C287.374,-80.7153 287.561,-71.848 287.738,-63.4814\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"291.243,-63.3086 287.955,-53.2367 284.244,-63.1604 291.243,-63.3086\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\"><title>5</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"600.5,-53 406.5,-53 406.5,-0 600.5,-0 600.5,-53\"/>\r\n<text text-anchor=\"middle\" x=\"503.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 3.693166293648493e+16</text>\r\n<text text-anchor=\"middle\" x=\"503.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 85</text>\r\n<text text-anchor=\"middle\" x=\"503.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 438524597.882</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M504.8,-88.9485C504.626,-80.7153 504.439,-71.848 504.262,-63.4814\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"507.756,-63.1604 504.045,-53.2367 500.757,-63.3086 507.756,-63.1604\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\"><title>6</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"820,-53 619,-53 619,-0 820,-0 820,-53\"/>\r\n<text text-anchor=\"middle\" x=\"719.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 1.2505386366560589e+17</text>\r\n<text text-anchor=\"middle\" x=\"719.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 57</text>\r\n<text text-anchor=\"middle\" x=\"719.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 856840313.649</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M580.347,-88.9485C603.758,-78.6102 629.434,-67.2722 652.286,-57.1809\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"653.824,-60.328 661.558,-53.0867 650.996,-53.9246 653.824,-60.328\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "graphviz.Source(treedot)  #Con graghviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Algoritmos de arbol son parecidos a una busqueda exhaustiva, voy a probar todas las features y luego para cada feature voy a dividir mis datos en dos, con una separación arbitraria, datos cuyo valor sean menor a uno y datos mayores a 1.\n",
    "\n",
    "En caso de una clasificacion se debe predecir bien la clase. Y en caso de una regresion veo si el promedio apunta bien a las separaciones. \n",
    "\n",
    "Y por todo este analisis exhaustivo a traves de la features se escoge el mejor\n",
    "\n",
    "Se tiene en cuenta la suma de las distancias cuadráticas en la regresión aplicada al árbol. Se elige la mejor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtudes de los arboles de decision:\n",
    "\n",
    "- Metodo poderoso y probado\n",
    "- Interpretable\n",
    "- No necesita escalar los datos (clasificación), y menos preprocesamiento de variables\n",
    "\n",
    "Sin embargo en la practica existen modelos que obtienen mejor rendimiento. Como mejorar el modelo de arboles de decisión?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "**Concepto General**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest y Gradient Boosted Trees, forman parte de una familia de algoritmos que se denominan ensembles.\n",
    "\n",
    "$$ Ensemble = Submodelos \\rightarrow Entrenamiento \\rightarrow Predicciones_{Intermedias} \\rightarrow Voto \\rightarrow Prediccion_{final}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest y Gradient Boosting Trees, son del tipo Modelo Ensemble, que son un conjunto de varios modelos que son entrenados por separado, para luego votar o se promedian para obtener una mejor predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cómo funciona el algoritmo Random Forest?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar cientos de modelos de arboles de decisión que serán entrenados sobre **conjuntos de datos bootstrapeados** del conjunto de datos original y donde para cada etapa de separación el **conjunto de features elegibles** sera un subconjunto aleatorio del conjunto original de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../vol/img/rf_tree.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los arboles entrenados luego podrá votar por su predicción y promediaremos estos votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../vol/img/random_forest.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensembles del pobre (\"Poor man's ensembles\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entrenar diversos modelos a mano\n",
    "- Promediar el resultado\n",
    "- Owen Zhang, número 1 de Kaggle.com durante un largo tiempo, ocupaba esta estrategia promediando diversos modelos XGBoost.\n",
    "- ``from sklearn.ensemble import VotingClassifier`` sirve por ejemplo para hacer un ensemble manual de clasificación\n",
    "\n",
    "En general los ensembles del pobre funcionan ya que cada uno de los modelos que votarán en conjunto son bastante fuertes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Porqué RF es poderoso?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  **Leo Breiman** creador del Random Forest demostró que un ensemble podía tener buen poder de generalización sí:\n",
    "  <ol>\n",
    "    <li>Los submodelos tienen buen poder de predicción</li>\n",
    "    <li>Los submodelos están descorrelacionados</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así el algoritmo de Random Forest compromete un poco de poder de predicción de cada uno de los decision trees que arma, pero la forma aleatoria de generarlos hace que esten **fuertemente descorrelacionados**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor   #Este modelo de arbol es para la regresion \n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "forest = RandomForestRegressor(200)   #200 parametro (Cantidad de arboles que va a generar) \n",
    "results = cross_validate(forest,X,y,cv=5,scoring='r2',return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'fit_time': array([1.34109879, 1.32209897, 1.42010498, 1.33809876, 1.3320992 ]),\n 'score_time': array([0.01800132, 0.01900101, 0.02600312, 0.02200174, 0.01900101]),\n 'test_score': array([0.45106959, 0.6774337 , 0.58578484, 0.40839254, 0.45955881]),\n 'train_score': array([0.96092374, 0.96489724, 0.96770015, 0.96264891, 0.96528162])}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9642903325250514\n0.5164478946208455\n"
    }
   ],
   "source": [
    "test_scores = results['test_score']\n",
    "train_scores = results['train_score']\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor resultado que Lasso! Ya no tenemos Sesgo y tenemos un mejor score r2. Sin embargo tenemos una diferencia importante entre score de entrenamiento y de test (overfit).\n",
    "\n",
    "El Lasso tenia sesgo, el modelo era demasiado simple, y aqui con el RandomForestRegressor el modelo es mas complejo y logra acercarse muy bien al train pero no lo estamos regularizando bien en sus parametros para que no overfitee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees   (Utilizamos este por que es mas complejo y vamos a regualizar el overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "ensemble = GradientBoostingRegressor()\n",
    "results = cross_validate(ensemble,X,y,cv=5,scoring='r2',return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9144608683148601\n0.5315940100689043\n"
    }
   ],
   "source": [
    "test_scores = results['test_score']\n",
    "train_scores = results['train_score']\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo optimizamos los parametros de este último modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fijar un learning rate alto\n",
    "- Fijar parametros de los arboles\n",
    "- Fijados estos parametros, elegir el mejor numero de estimadores que conforman el ensemble\n",
    "- (Tarea) Con el learning rate dado y el numero de estimadores óptimo, optimizar los parametros de los arboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ahora dijimos que:\n",
    "    \n",
    "- train_test_split servia para evaluaciones rapidas, testeos y prototipaje\n",
    "- cross_validate es un método más robusto para poder estimar el rendimiento de tu algoritmo\n",
    "\n",
    "Sin embargo una vez que hemos finalizado nuestra etapa de prototipaje y ya queremos establecer un modelo definitivo deberiamos seguir el flujo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../vol/img/grid_search_crossval.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la etapa final lo que se debe hacer es separar los datos, en datos de entrenamiento y datos de test, pero los de test se van a dejar aparte, solo se usarán al final para obtener el score que se entregará al interesado.\n",
    "Para ver el score en las iteraciones se debe separar la parte de los datos de entrenamiento en un nuevo set de entrenamiento y en un set de datos de validación, de ésta forma podemos mejorar los parámetros y los score.\n",
    "\n",
    "En resumen se tiene que los Gradient Boosting Grid son complejos de optimizar, aunque algunos Kaggle proporcionan la siguiente receta para lograr esto:\n",
    "\n",
    "Elige primero un learning rate, que es uno de los parámetros del algoritmo, que sea aproximadamente 0.1.\n",
    "Después fija todos los parámetros de árbol (recuerda que los GBG, los modelos de aprendizaje débil, son arboles) que sean relativamente buenos para esos pequeños arboles.\n",
    "Luego, con GridSearch busca el mejor valor para la cantidad de estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_test1 = {'n_estimators': range(20,501,20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[20,\n 40,\n 60,\n 80,\n 100,\n 120,\n 140,\n 160,\n 180,\n 200,\n 220,\n 240,\n 260,\n 280,\n 300,\n 320,\n 340,\n 360,\n 380,\n 400,\n 420,\n 440,\n 460,\n 480,\n 500]"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "list(param_test1['n_estimators'])  #Se van a testear estos valores, para ver cual es el mejor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                     min_samples_split=500,\n",
    "                                     min_samples_leaf=50,\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gsearch1 = GridSearchCV(estimator, \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='r2', \n",
    "                        cv=5,\n",
    "                        return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n                                                 criterion='friedman_mse',\n                                                 init=None, learning_rate=0.1,\n                                                 loss='ls', max_depth=8,\n                                                 max_features='sqrt',\n                                                 max_leaf_nodes=None,\n                                                 min_impurity_decrease=0.0,\n                                                 min_impurity_split=None,\n                                                 min_samples_leaf=50,\n                                                 min_samples_split=500,\n                                                 min_weight_fraction_leaf=0.0,\n                                                 n_estimators=100,\n                                                 n_iter_no_change=None,\n                                                 presort='deprecated',\n                                                 random_state=10, subsample=0.8,\n                                                 tol=0.0001,\n                                                 validation_fraction=0.1,\n                                                 verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=None,\n             param_grid={'n_estimators': range(20, 501, 20)},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n             scoring='r2', verbose=0)"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([(0.6190451393262852, 0.07790466000268802, {'n_estimators': 20}),\n  (0.6866996104035019, 0.0572125247531653, {'n_estimators': 40}),\n  (0.6998873491605904, 0.049898530169396466, {'n_estimators': 60}),\n  (0.7050046084079756, 0.04587990450263335, {'n_estimators': 80}),\n  (0.7081158100185159, 0.043420317027916454, {'n_estimators': 100}),\n  (0.7124807791392783, 0.04145433982947511, {'n_estimators': 120}),\n  (0.7153633282508316, 0.04180856749234244, {'n_estimators': 140}),\n  (0.7164224396160013, 0.040336257275822185, {'n_estimators': 160}),\n  (0.7173562531963734, 0.03981294993202842, {'n_estimators': 180}),\n  (0.7181921814130573, 0.0390702749330308, {'n_estimators': 200}),\n  (0.7189062913607358, 0.03827933149592073, {'n_estimators': 220}),\n  (0.718189319798347, 0.037150635458503625, {'n_estimators': 240}),\n  (0.718511926981295, 0.03576211518782603, {'n_estimators': 260}),\n  (0.718710543417778, 0.034760646805813, {'n_estimators': 280}),\n  (0.7193820668878087, 0.035931731707671125, {'n_estimators': 300}),\n  (0.7187658890071879, 0.03590206224620174, {'n_estimators': 320}),\n  (0.7184320148957128, 0.035040152968881855, {'n_estimators': 340}),\n  (0.7185735687188051, 0.03512663483940705, {'n_estimators': 360}),\n  (0.7175923965590979, 0.03525921616310885, {'n_estimators': 380}),\n  (0.7173153752008578, 0.03403524499830451, {'n_estimators': 400}),\n  (0.7174154036413807, 0.033409318603757024, {'n_estimators': 420}),\n  (0.7176263179308766, 0.033917273428193964, {'n_estimators': 440}),\n  (0.7174703803000858, 0.03261099525589868, {'n_estimators': 460}),\n  (0.7169654296115792, 0.03227252039925173, {'n_estimators': 480}),\n  (0.7169224267224464, 0.032987381405431955, {'n_estimators': 500})],\n {'n_estimators': 300},\n 0.7193820668878087)"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "list(zip(gsearch1.cv_results_['mean_test_score'], \n",
    "         gsearch1.cv_results_['std_test_score'], \n",
    "         gsearch1.cv_results_['params'])), gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gsearch1.best_estimator_      #Nos da el resultado de arriba n_estimators: 280 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = cross_validate(gsearch1.best_estimator_,X_train,y_train,return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8265168662364198\n0.7193820668878087\n"
    }
   ],
   "source": [
    "test_scores = final_results['test_score']      #Nuestra cross_validation llega a un asituacion ideal eliminamos el overfiting\n",
    "train_scores = final_results['train_score']\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingRegressor(learning_rate=0.1,\n",
    "                                     min_samples_split=500,\n",
    "                                     min_samples_leaf=50,\n",
    "                                     max_depth=8,\n",
    "                                     max_features='sqrt',\n",
    "                                     subsample=0.8,\n",
    "                                     random_state=10,\n",
    "                                     n_estimators=300)   #Poner el mejor estimador que se saco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n                          init=None, learning_rate=0.1, loss='ls', max_depth=8,\n                          max_features='sqrt', max_leaf_nodes=None,\n                          min_impurity_decrease=0.0, min_impurity_split=None,\n                          min_samples_leaf=50, min_samples_split=500,\n                          min_weight_fraction_leaf=0.0, n_estimators=300,\n                          n_iter_no_change=None, presort='deprecated',\n                          random_state=10, subsample=0.8, tol=0.0001,\n                          validation_fraction=0.1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7880420602428624"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "estimator.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión de todo el analisis, pasamos de un score de 40% a 78% en R2, gracias a haber trabajdo sobre las features, haber entendido si estaba funcionando nuestro 1er modelo, probar otros modelos y finalmente con GridSearchCv haber optimizado nuestros parametros de nuestro modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflexiones de cierre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recursos **\n",
    "\n",
    "- Reddit /machinelearning y /learnmachinelearning\n",
    "- Analytics Vidhya y KD Nuggets\n",
    "- Kaggle.com y \"There is no Free Hunch\" Blog\n",
    "- Arxiv, papers\n",
    "- Libros: \"Pattern Recognition and Machine Learning\" C.Bishop y \"Elements of Statistical Learning\".\n",
    "\n",
    "** Próximos pasos **\n",
    "\n",
    "- Matemáticas\n",
    "- Praxis: Feature Engineering, Model Selection y Tuning\n",
    "- Deep Learning para NLP y Computer Vision\n",
    "- Machine Learning Bayesiano"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('Anaconda': conda)",
   "language": "python",
   "name": "python37464bitanacondaconda74954a3f106b47d99d44e5fb8ca66932"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}